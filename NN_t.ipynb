{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "from random import randint\n",
    "from scipy import misc\n",
    "from scipy import special\n",
    "import scipy.ndimage\n",
    "from scipy.sparse import csc_matrix, issparse\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "\n",
    "#setting path\n",
    "DATA_PATH = '/home/giosumarin/Scrivania/CANN-master/compression_algorithms/data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN = 'data_training'\n",
    "IMAGES_TEST = 'data_testing'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28\n",
    "\n",
    "#import data+label\n",
    "data_training = DATA_PATH+IMAGES_TRAIN\n",
    "data_testing = DATA_PATH+IMAGES_TEST\n",
    "ft = gzip.open(data_training, 'rb')\n",
    "TRAINING = pickle.load(ft)\n",
    "ft.close()\n",
    "ft = gzip.open(data_testing, 'rb')\n",
    "TESTING = pickle.load(ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, neurons, stop_parameter):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.stop_p = stop_parameter\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        \n",
    "        #create random matrix for wheights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = np.random.rand(self.neurons, self.input_size + 1)/self.neurons\n",
    "        output_layer = np.random.rand(self.output_size, self.neurons + 1) / self.output_size\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "        \n",
    "    def train (self, training, testing):\n",
    "        accu_train = [0., 0.]\n",
    "        len_train = len(training[0])\n",
    "        len_test = len(testing[0])\n",
    "        self.start_time = dt.datetime.now()\n",
    "        typeTrainingPrint = \"Stop Function: \" \n",
    "        typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        print(typeTrainingPrint)\n",
    "        #print('\\nNeurons: %d\\nBatch Train: %d\\nBatch Test: %d\\n%s\\n' % (self.neurons,len_batch_train,len_batch_test,typeTrainingPrint))\n",
    "        inputs = training[0][0:len_train]\n",
    "        targets = np.zeros((len_train, 10))\n",
    "        for i in range(len_train):\n",
    "            targets[i, training[1][i]] = 1\n",
    "        \n",
    "        while not self.is_stop_function(accu_train[1]):\n",
    "            self.iteration += 1\n",
    "        \n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backprop(input_vector, target_vector)\n",
    "        \n",
    "        \n",
    "            accu_test = self.accu(testing)\n",
    "            accu_test = self.accu(training)\n",
    "            \n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1) \n",
    "            output = np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            \n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backprop(self, input_vector, target):\n",
    "        c = 10**(-4) + 10**(-1)/math.sqrt(self.iteration)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        \n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], self.neurons, 1).T, output_deltas)\n",
    "        self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "    \n",
    "    def accu(self, testing):\n",
    "        res= np.zeros((10, 2))\n",
    "        #se giusto aggiungo 1 ad entrambe le colonne di res (colonne = giusti, totali)\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        return np.round(total[0]/total[1]*100, 2)\n",
    "    \n",
    "    def is_stop_function(self, accuracy):\n",
    "        if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "            self.best = accuracy\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "    def print_message_iter(self,iteration,accu_test,accu_train,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"\n",
    "        message += 'Accuracy TRAIN: '+str(accu_train).zfill(4)+'%\\t'\n",
    "        message += 'Accuracy TEST: '+str(accu_test).zfill(4)+'%\\t'\n",
    "        print(message)\n",
    "        \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Function: improvements below 0.01%\n",
      "Epoch 001 (29s)    Accuracy TRAIN: [0.0, 0.0]%\tAccuracy TEST: 92.84%\t\n",
      "Epoch 001 (29s)    Accuracy TRAIN: [0.0, 0.0]%\tAccuracy TEST: 92.84%\t\n",
      "\n",
      "-- Training Session End (2019-05-09 18:28:24.956923) --\n"
     ]
    }
   ],
   "source": [
    "nn = NN(neurons=100, stop_parameter=0.01)\n",
    "nn.train(TRAINING[0:1000], TESTING[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
