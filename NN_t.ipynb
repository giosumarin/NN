{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-54bac71acd70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdata_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mIMAGES_TEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mTRAINING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_testing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "from random import randint\n",
    "from scipy import misc\n",
    "from scipy import special\n",
    "import scipy.ndimage\n",
    "from scipy.sparse import csc_matrix, issparse\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "\n",
    "#setting path\n",
    "DATA_PATH = 'data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN = 'data_training'\n",
    "IMAGES_TEST = 'data_testing'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28\n",
    "\n",
    "#import data+label\n",
    "data_training = DATA_PATH+IMAGES_TRAIN\n",
    "data_testing = DATA_PATH+IMAGES_TEST\n",
    "ft = gzip.open(data_training, 'rb')\n",
    "TRAINING = pickle.load(ft)\n",
    "ft.close()\n",
    "ft = gzip.open(data_testing, 'rb')\n",
    "TESTING = pickle.load(ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, neurons, stop_parameter, stop_function):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.stop_p = stop_parameter\n",
    "        self.stop_f = stop_function\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        self.limit_epoch = 10\n",
    "        \n",
    "        #create random matrix for wheights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = np.random.rand(self.neurons, self.input_size + 1)/self.neurons\n",
    "        output_layer = np.random.rand(self.output_size, self.neurons + 1) / self.output_size\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "        \n",
    "    def train (self, training, testing):\n",
    "        accu_train = 0. #[0., 0.]\n",
    "        len_train = len(training[0])\n",
    "        len_test = len(testing[0])\n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('\\n-- Training Session Start (%s) --' % (dt.datetime.now()))\n",
    "        typeTrainingPrint = \"Stop Function: \" \n",
    "        if(self.stop_f==0):\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        else:\n",
    "            typeTrainingPrint += \"after \"+str(self.limit_epoch)+\" epochs\"\n",
    "        print(typeTrainingPrint)\n",
    "        inputs = training[0][0:len_train]\n",
    "        targets = np.zeros((len_train, 10))\n",
    "        for i in range(len_train):\n",
    "            targets[i, training[1][i]] = 1 #metto 1 nella posizione del valore della label\n",
    "        \n",
    "        while not self.is_stop_function(accu_train): #(accu_train[1]):\n",
    "            self.iteration += 1\n",
    "        \n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backprop(input_vector, target_vector)\n",
    "        \n",
    "        \n",
    "            accu_test = self.accu(testing)\n",
    "            accu_train = self.accu(training)\n",
    "                \n",
    "            #print (accu_train)\n",
    "            \n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1) \n",
    "            output = np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            \n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backprop(self, input_vector, target):\n",
    "        c = 10**(-4) + 10**(-1)/math.sqrt(self.iteration)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        \n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], self.neurons, 1).T, output_deltas)\n",
    "        self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "    \n",
    "    def accu(self, testing):\n",
    "        res= np.zeros((10, 2))\n",
    "        #se giusto aggiungo 1 ad entrambe le colonne di res (colonne = giusti, totali)\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        return np.round(total[0]/total[1]*100, 2)\n",
    "    \n",
    "    def is_stop_function(self, accuracy):\n",
    "        if self.stop_f==0:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f==1:\n",
    "            if self.iteration>=self.limit_epoch:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def print_message_iter(self,iteration,accu_test,accu_train,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"+'Accuracy TRAIN: '+str(accu_train).zfill(4)+'%\\t'+'Accuracy TEST: '+str(accu_test).zfill(4)+'%\\t'\n",
    "        print(message)\n",
    "        \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "    def getWeight(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-10 20:18:12.002720) --\n",
      "Stop Function: improvements below 0.01%\n",
      "Epoch 001 (9s)     Accuracy TRAIN: 89.84%\tAccuracy TEST: 88.18%\t\n",
      "Epoch 010 (1m22s)  Accuracy TRAIN: 95.53%\tAccuracy TEST: 93.23%\t\n",
      "Epoch 020 (2m42s)  Accuracy TRAIN: 96.78%\tAccuracy TEST: 94.05%\t\n",
      "Epoch 030 (4m5s)   Accuracy TRAIN: 97.28%\tAccuracy TEST: 94.48%\t\n",
      "Epoch 037 (5m3s)   Accuracy TRAIN: 97.56%\tAccuracy TEST: 94.58%\t\n",
      "\n",
      "-- Training Session End (2019-05-10 20:23:15.420716) --\n"
     ]
    }
   ],
   "source": [
    "nn = NN(neurons=100, stop_function=0, stop_parameter=0.01)\n",
    "nn.train([TRAINING[0][0:12000],TRAINING[1][0:12000]], TESTING)\n",
    "#[TRAINING[0][0:1000],TRAINING[1][0:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-10 15:50:01.829679) --\n",
      "Stop Function: after 10 epochs\n",
      "Epoch 001 (30s)    Accuracy TRAIN: 92.84%\tAccuracy TEST: 93.04%\t\n",
      "Epoch 002 (1m2s)   Accuracy TRAIN: 95.18%\tAccuracy TEST: 95.03%\t\n",
      "Epoch 003 (1m32s)  Accuracy TRAIN: 96.05%\tAccuracy TEST: 95.74%\t\n",
      "Epoch 004 (2m2s)   Accuracy TRAIN: 96.62%\tAccuracy TEST: 96.13%\t\n",
      "Epoch 005 (2m32s)  Accuracy TRAIN: 96.95%\tAccuracy TEST: 96.39%\t\n",
      "Epoch 006 (3m1s)   Accuracy TRAIN: 97.28%\tAccuracy TEST: 96.62%\t\n",
      "Epoch 007 (3m31s)  Accuracy TRAIN: 97.55%\tAccuracy TEST: 96.77%\t\n",
      "Epoch 008 (4m1s)   Accuracy TRAIN: 97.72%\tAccuracy TEST: 96.91%\t\n",
      "Epoch 009 (4m31s)  Accuracy TRAIN: 97.86%\tAccuracy TEST: 96.98%\t\n",
      "Epoch 010 (5m1s)   Accuracy TRAIN: 98.01%\tAccuracy TEST: 97.03%\t\n",
      "\n",
      "-- Training Session End (2019-05-10 15:55:03.607212) --\n"
     ]
    }
   ],
   "source": [
    "nn = NN(neurons=100, stop_function=1, stop_parameter=0.05)\n",
    "nn.train(TRAINING, TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_matrix(mat, percentage):\n",
    "    threshold = (100-percentage)\n",
    "    threshold /= 2\n",
    "    perc_up, perc_down = 100 - threshold, threshold\n",
    "    percentile_up = np.percentile(mat, perc_up)\n",
    "    percentile_down = np.percentile(mat, perc_down)\n",
    "    \n",
    "    w_pruned = np.copy(mat)\n",
    "    for i,row in enumerate(mat):\n",
    "        for j,_ in enumerate(row):\n",
    "            if mat[i,j] < percentile_down or mat[i,j] > percentile_up:\n",
    "                w_pruned[i,j] = 0\n",
    "    return w_pruned\n",
    "\n",
    "def sparse_sub_dense(sparse,dense,mask):\n",
    "    sparse.data -= dense.T[mask.T]\n",
    "\n",
    "def delete_last_row(csc):\n",
    "    i = csc.indptr[-1]\n",
    "    indptr = csc.indptr[:-1]\n",
    "    data = csc.data[:i]\n",
    "    indices = csc.indices[:i]\n",
    "    return csc_matrix((data,indices,indptr))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Pr:\n",
    "    def __init__(self, neurons, stop_parameter, stop_function, pruning, weights):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.stop_p = stop_parameter\n",
    "        self.stop_f = stop_function\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        self.limit_epoch = 5\n",
    "        self.pruning = pruning\n",
    "        self.weights = weights\n",
    "        \n",
    "        #create random matrix for wheights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = csc_matrix(pruning_matrix(weights[0], pruning))\n",
    "        output_layer = csc_matrix(pruning_matrix(weights[1], pruning))\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "        \n",
    "        mask_hidden = hidden_layer.A != 0\n",
    "        mask_output = output_layer.A != 0\n",
    "        self.mask = [mask_hidden, mask_output]\n",
    "        \n",
    "    def train (self, training, testing):\n",
    "        accu_train = 0.\n",
    "        len_train = len(training[0])\n",
    "        len_test = len(testing[0])\n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('\\n-- Training Session Start (%s) --' % (dt.datetime.now()))\n",
    "        typeTrainingPrint = \"Stop Function: \" \n",
    "        if(self.stop_f==0):\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        else:\n",
    "            typeTrainingPrint += \"after \"+str(self.limit_epoch)+\" epochs\"\n",
    "        print(typeTrainingPrint)\n",
    "        inputs = training[0][0:len_train]\n",
    "        targets = np.zeros((len_train, 10))\n",
    "        for i in range(len_train):\n",
    "            targets[i, training[1][i]] = 1 #metto 1 nella posizione del valore della label\n",
    "        \n",
    "        while not self.is_stop_function(accu_train): #(accu_train[1]):\n",
    "            self.iteration += 1\n",
    "        \n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.backprop(input_vector, target_vector)\n",
    "        \n",
    "        \n",
    "            accu_test = self.accu(testing)\n",
    "            accu_train = self.accu(training)\n",
    "                \n",
    "            #print (accu_train)\n",
    "            \n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, input_vector):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            input_with_bias = np.append(input_vector, 1) \n",
    "            output = layer * input_with_bias #np.inner(layer, input_with_bias)\n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            \n",
    "            input_vector = output\n",
    "        return outputs\n",
    "\n",
    "    def backprop(self, input_vector, target):\n",
    "        c = 10**(-4) + 10**(-1)/math.sqrt(self.iteration)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(input_vector)\n",
    "        \n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target)\n",
    "        #self.layers[-1] -= c*np.outer(output_deltas, np.append(hidden_outputs, 1))\n",
    "        sparse_sub_dense(self.layers[-1], c*np.outer(output_deltas, np.append(hidden_outputs, 1)), self.mask[-1])\n",
    "        \n",
    "        #hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(np.delete(self.layers[-1], self.neurons, 1).T, output_deltas)\n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * (delete_last_row(self.layers[-1]).T * output_deltas)\n",
    "        sparse_sub_dense(self.layers[0], c*np.outer(hidden_deltas, np.append(input_vector, 1)), self.mask[0])\n",
    "\n",
    "        #self.layers[0] -= c*np.outer(hidden_deltas, np.append(input_vector, 1))\n",
    "        \n",
    "    def predict(self, input_vector):\n",
    "        return self.feed_forward(input_vector)[-1]\n",
    "\n",
    "    def predict_one(self, input_vector):\n",
    "        return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "    \n",
    "    def accu(self, testing):\n",
    "        res= np.zeros((10, 2))\n",
    "        #se giusto aggiungo 1 ad entrambe le colonne di res (colonne = giusti, totali)\n",
    "        for k in range(len(testing[1])):\n",
    "            if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        return np.round(total[0]/total[1]*100, 2)\n",
    "    \n",
    "    def is_stop_function(self, accuracy):\n",
    "        if self.stop_f==0:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f==1:\n",
    "            if self.iteration>=self.limit_epoch:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def print_message_iter(self,iteration,accu_test,accu_train,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"+'Accuracy TRAIN: '+str(accu_train).zfill(4)+'%\\t'+'Accuracy TEST: '+str(accu_test).zfill(4)+'%\\t'\n",
    "        print(message)\n",
    "        \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "    def getWeight(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-10 20:26:31.137213) --\n",
      "Stop Function: improvements below 0.01%\n",
      "Epoch 001 (16s)    Accuracy TRAIN: 89.42%\tAccuracy TEST: 88.12%\t\n",
      "Epoch 010 (2m41s)  Accuracy TRAIN: 95.1%\tAccuracy TEST: 93.12%\t\n",
      "Epoch 020 (5m22s)  Accuracy TRAIN: 96.34%\tAccuracy TEST: 93.89%\t\n",
      "Epoch 030 (8m4s)   Accuracy TRAIN: 96.89%\tAccuracy TEST: 94.12%\t\n",
      "Epoch 039 (10m39s) Accuracy TRAIN: 97.26%\tAccuracy TEST: 94.48%\t\n",
      "\n",
      "-- Training Session End (2019-05-10 20:37:10.862413) --\n"
     ]
    }
   ],
   "source": [
    "w=nn.getWeight()\n",
    "nnp = NN_Pr(neurons=100, stop_function=0, stop_parameter=0.01, pruning=75, weights=w)\n",
    "nnp.train([TRAINING[0][0:12000],TRAINING[1][0:12000]], TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-10 20:06:09.907970) --\n",
      "Stop Function: improvements below 0.01%\n",
      "Epoch 001 (16s)    Accuracy TRAIN: 87.27%\tAccuracy TEST: 86.0%\t\n",
      "Epoch 002 (33s)    Accuracy TRAIN: 89.99%\tAccuracy TEST: 88.0%\t\n",
      "Epoch 003 (49s)    Accuracy TRAIN: 90.97%\tAccuracy TEST: 89.0%\t\n",
      "Epoch 004 (1m5s)   Accuracy TRAIN: 91.63%\tAccuracy TEST: 89.6%\t\n",
      "Epoch 005 (1m21s)  Accuracy TRAIN: 92.24%\tAccuracy TEST: 90.4%\t\n",
      "Epoch 006 (1m36s)  Accuracy TRAIN: 92.61%\tAccuracy TEST: 91.0%\t\n",
      "Epoch 007 (1m52s)  Accuracy TRAIN: 93.09%\tAccuracy TEST: 90.8%\t\n",
      "Epoch 008 (2m8s)   Accuracy TRAIN: 93.24%\tAccuracy TEST: 90.8%\t\n",
      "Epoch 009 (2m23s)  Accuracy TRAIN: 93.43%\tAccuracy TEST: 91.0%\t\n",
      "Epoch 010 (2m39s)  Accuracy TRAIN: 93.6%\tAccuracy TEST: 91.2%\t\n",
      "Epoch 011 (2m56s)  Accuracy TRAIN: 93.73%\tAccuracy TEST: 91.2%\t\n",
      "Epoch 012 (3m14s)  Accuracy TRAIN: 93.87%\tAccuracy TEST: 91.4%\t\n",
      "Epoch 013 (3m29s)  Accuracy TRAIN: 93.96%\tAccuracy TEST: 91.4%\t\n",
      "Epoch 014 (3m45s)  Accuracy TRAIN: 94.06%\tAccuracy TEST: 91.2%\t\n",
      "Epoch 015 (4m0s)   Accuracy TRAIN: 94.13%\tAccuracy TEST: 91.2%\t\n",
      "Epoch 016 (4m15s)  Accuracy TRAIN: 94.19%\tAccuracy TEST: 91.2%\t\n",
      "Epoch 017 (4m31s)  Accuracy TRAIN: 94.3%\tAccuracy TEST: 91.4%\t\n",
      "Epoch 018 (4m46s)  Accuracy TRAIN: 94.43%\tAccuracy TEST: 91.4%\t\n",
      "Epoch 019 (5m1s)   Accuracy TRAIN: 94.53%\tAccuracy TEST: 91.6%\t\n",
      "Epoch 020 (5m17s)  Accuracy TRAIN: 94.61%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 021 (5m32s)  Accuracy TRAIN: 94.7%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 022 (5m48s)  Accuracy TRAIN: 94.79%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 023 (6m3s)   Accuracy TRAIN: 94.84%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 024 (6m18s)  Accuracy TRAIN: 94.91%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 025 (6m34s)  Accuracy TRAIN: 94.96%\tAccuracy TEST: 91.8%\t\n",
      "Epoch 026 (6m49s)  Accuracy TRAIN: 95.09%\tAccuracy TEST: 92.2%\t\n",
      "Epoch 027 (7m4s)   Accuracy TRAIN: 95.17%\tAccuracy TEST: 92.2%\t\n",
      "Epoch 028 (7m20s)  Accuracy TRAIN: 95.24%\tAccuracy TEST: 92.2%\t\n",
      "Epoch 029 (7m35s)  Accuracy TRAIN: 95.26%\tAccuracy TEST: 92.2%\t\n",
      "Epoch 030 (7m51s)  Accuracy TRAIN: 95.27%\tAccuracy TEST: 92.2%\t\n",
      "\n",
      "-- Training Session End (2019-05-10 20:14:01.010891) --\n"
     ]
    }
   ],
   "source": [
    "w=nn.getWeight()\n",
    "nnp1 = NN_Pr(neurons=100, stop_function=0, stop_parameter=0.01, pruning=60, weights=w)\n",
    "nnp1.train([TRAINING[0][0:7000],TRAINING[1][0:7000]], [TESTING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1, 2, 3], [3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  2],\n",
       "       [ 4,  4],\n",
       "       [ 6,  6],\n",
       "       [ 6,  6],\n",
       "       [ 8,  8],\n",
       "       [10, 10]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([2,2])\n",
    "np.outer(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import gzip\n",
    "from random import randint\n",
    "from scipy import misc\n",
    "from scipy import special\n",
    "import scipy.ndimage\n",
    "from scipy.sparse import csc_matrix, issparse\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "\n",
    "#setting path\n",
    "DATA_PATH = 'data/mnist/'\n",
    "\n",
    "IMAGES_TRAIN = 'data_training'\n",
    "IMAGES_TEST = 'data_testing'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_CLASSES = 10\n",
    "N_FEATURES = 28 * 28\n",
    "\n",
    "#import data+label\n",
    "data_training = DATA_PATH+IMAGES_TRAIN\n",
    "data_testing = DATA_PATH+IMAGES_TEST\n",
    "ft = gzip.open(data_training, 'rb')\n",
    "TRAINING = pickle.load(ft)\n",
    "ft.close()\n",
    "ft = gzip.open(data_testing, 'rb')\n",
    "TESTING = pickle.load(ft)\n",
    "ft.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_b:\n",
    "    def __init__(self, neurons, stop_parameter, stop_function):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.stop_p = stop_parameter\n",
    "        self.stop_f = stop_function\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        self.limit_epoch = 20\n",
    "        \n",
    "        #create random matrix for wheights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        hidden_layer = np.random.rand(self.input_size, self.neurons)/self.neurons #self.neurons\n",
    "        output_layer = np.random.rand(self.neurons, self.output_size)/self.output_size #self.output_size\n",
    "        self.layers = [hidden_layer, output_layer]\n",
    "        \n",
    "    def train (self, training, testing):\n",
    "        accu_train = 0.\n",
    "        len_train = len(training[0])\n",
    "        len_test = len(testing[0])\n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('\\n-- Training Session Start (%s) --' % (dt.datetime.now()))\n",
    "        typeTrainingPrint = \"Stop Function: \" \n",
    "        if(self.stop_f==0):\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        else:\n",
    "            typeTrainingPrint += \"after \"+str(self.limit_epoch)+\" epochs\"\n",
    "        print(typeTrainingPrint)\n",
    "        inputs = training[0][0:len_train]\n",
    "        targets = np.zeros((len_train, 10))\n",
    "        for i in range(len_train):\n",
    "            targets[i, training[1][i]] = 1 #metto 1 nella posizione del valore della label\n",
    "        #print(np.argmax(targets[3]))\n",
    "        #print(targets.shape)\n",
    "        \n",
    "        #onesForInput = np.ones((inputs.shape[0],1))\n",
    "        #inputsWithB = np.hstack((inputs,onesForInput))\n",
    "        \n",
    "        while not self.is_stop_function(accu_train): \n",
    "            self.iteration += 1\n",
    "        \n",
    "            #for input_vector, target_vector in zip(inputs, targets):\n",
    "            \n",
    "            self.backprop(inputs, targets)\n",
    "        \n",
    "        \n",
    "            accu_test = self.accu(testing)\n",
    "            accu_train = self.accu(training)\n",
    "                \n",
    "            #print (accu_train)\n",
    "            \n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "        outputs = []\n",
    "        for layer in self.layers:\n",
    "            #da fare successivamente a monte    input_with_bias = np.append(input_vector, 1) \n",
    "            output = np.dot(inputs, layer) \n",
    "            output = special.expit(output)\n",
    "            outputs.append(output)\n",
    "            \n",
    "            inputs = output\n",
    "        return outputs #NumEsempi x neuroni; NumEsempi x classi\n",
    "\n",
    "    def backprop(self, inputs, target):\n",
    "        c = 10**(-4) + 10**(-1)/math.sqrt(self.iteration)  # Learning coefficient\n",
    "        hidden_outputs, outputs = self.feed_forward(inputs)\n",
    "        #print(hidden_outputs.shape)\n",
    "        #print(outputs.shape)\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target) #NumEx x Output\n",
    "        #print(hidden_outputs.shape)\n",
    "        #print((np.dot(output_deltas.T, hidden_outputs)).shape)\n",
    "        #print(outputs-target)\n",
    "        #print(target.shape)\n",
    "        \n",
    "        hidden_deltas = hidden_outputs * (1 - hidden_outputs) * np.dot(output_deltas, self.layers[-1].T)\n",
    "        \n",
    "        self.layers[-1] -= c * (np.dot(hidden_outputs.T, output_deltas))\n",
    "\n",
    "        self.layers[0] -= c * np.dot(inputs.T, hidden_deltas)\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        return self.feed_forward(inputs)[-1]\n",
    "\n",
    "   #def predict_one(self, inputs):\n",
    "   #     return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "    \n",
    "    def accu(self, testing):\n",
    "        res= np.zeros((10, 2))\n",
    "        #se giusto aggiungo 1 ad entrambe le colonne di res (colonne = giusti, totali)\n",
    "        predicted = self.predict(testing[0])\n",
    "        for k in range(len(testing[1])):\n",
    "            if np.argmax(predicted[k]) == testing[1][k]:\n",
    "            #if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res[testing[1][k]] += 1\n",
    "            else:\n",
    "                res[testing[1][k]][1] += 1\n",
    "        total = np.sum(res, axis=0)\n",
    "        return np.round(total[0]/total[1]*100, 2)\n",
    "    \n",
    "    def is_stop_function(self, accuracy):\n",
    "        if self.stop_f==0:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f==1:\n",
    "            if self.iteration>=self.limit_epoch:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def print_message_iter(self,iteration,accu_test,accu_train,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"+'Accuracy TRAIN: '+str(accu_train).zfill(4)+'%\\t'+'Accuracy TEST: '+str(accu_test).zfill(4)+'%\\t'\n",
    "        print(message)\n",
    "        \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "    def getWeight(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-13 10:16:03.587707) --\n",
      "Stop Function: after 20 epochs\n",
      "[[ 0.97037534  0.94321644  0.95541696 ...  0.95405249  0.97017119\n",
      "   0.9592172 ]\n",
      " [-0.02707463  0.94690084  0.95875929 ...  0.95738776  0.97272245\n",
      "   0.96241579]\n",
      " [ 0.96399872  0.93370948  0.94716769 ...  0.94555946  0.96366503\n",
      "   0.95130194]\n",
      " ...\n",
      " [ 0.97078935  0.94364534  0.95601813 ...  0.95448788  0.97060701\n",
      "   0.95962127]\n",
      " [ 0.96369037  0.93331026  0.94686346 ...  0.94523083  0.96345459\n",
      "  -0.04898393]\n",
      " [ 0.96482428  0.93496939  0.94819043 ... -0.05325089  0.96458393\n",
      "   0.95238883]]\n",
      "Epoch 001 (0s)     Accuracy TRAIN: 10.01%\tAccuracy TEST: 09.8%\t\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "Epoch 010 (4s)     Accuracy TRAIN: 10.01%\tAccuracy TEST: 09.8%\t\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "[[ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [-0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " ...\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5 ...  0.5  0.5 -0.5]\n",
      " [ 0.5  0.5  0.5 ... -0.5  0.5  0.5]]\n",
      "Epoch 020 (7s)     Accuracy TRAIN: 10.01%\tAccuracy TEST: 09.8%\t\n",
      "\n",
      "-- Training Session End (2019-05-13 10:16:11.430434) --\n"
     ]
    }
   ],
   "source": [
    "nnM = NN_b(neurons=100, stop_function=1, stop_parameter=0.01)\n",
    "nnM.train([TRAINING[0][0:10000],TRAINING[1][0:10000]], TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56566473, 0.55671996, 0.56907456, 0.56892295, 0.5847587 ,\n",
       "       0.55187534, 0.56024951, 0.55870131, 0.55531596, 0.55184915])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.argmax\n",
    "(nnM.predict(TRAINING[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hidden_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-ab2ccfc1c37d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hidden_layer' is not defined"
     ]
    }
   ],
   "source": [
    "hidden_layer.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_b:\n",
    "    def __init__(self, neurons, stop_parameter, stop_function):\n",
    "        self.input_size = N_FEATURES\n",
    "        self.output_size = N_CLASSES\n",
    "        self.neurons = neurons\n",
    "        self.stop_p = stop_parameter\n",
    "        self.stop_f = stop_function\n",
    "        self.best = 0.\n",
    "        self.same = 0\n",
    "        self.iteration = 0\n",
    "        self.limit_epoch = 300\n",
    "        \n",
    "        #create random matrix for wheights\n",
    "        np.random.seed(RANDOM_SEED)\n",
    "        #hidden_layer = np.random.rand(self.input_size, self.neurons)/self.neurons #self.neurons\n",
    "        #self.layers = np.random.rand(self.input_size, 1)\n",
    "       # self.layers = np.random.randn(self.input_size, 1)\n",
    "        self.layers = np.zeros((self.input_size, 1))\n",
    "        \n",
    "    def train (self, training, testing):\n",
    "        accu_train = 0.\n",
    "        len_train = len(training[0])\n",
    "        len_test = len(testing[0])\n",
    "        self.start_time = dt.datetime.now()\n",
    "        print('\\n-- Training Session Start (%s) --' % (dt.datetime.now()))\n",
    "        typeTrainingPrint = \"Stop Function: \" \n",
    "        if(self.stop_f==0):\n",
    "            typeTrainingPrint += \"improvements below \"+str(self.stop_p)+\"%\"\n",
    "        else:\n",
    "            typeTrainingPrint += \"after \"+str(self.limit_epoch)+\" epochs\"\n",
    "        print(typeTrainingPrint)\n",
    "        inputs = training[0]\n",
    "        targets = np.zeros((len_train, 1))\n",
    "        for i in range(len_train):\n",
    "            if training[1][i] == 4:\n",
    "                targets[i,0] = 1 \n",
    "        \n",
    "            #targets[i, training[1][i]] = 1 #metto 1 nella posizione del valore della label\n",
    "        #print(np.argmax(targets[3]))\n",
    "        #print(targets)\n",
    "        \n",
    "        #onesForInput = np.ones((inputs.shape[0],1))\n",
    "        #inputsWithB = np.hstack((inputs,onesForInput))\n",
    "        \n",
    "        while not self.is_stop_function(accu_train): \n",
    "            self.iteration += 1\n",
    "        \n",
    "            #for input_vector, target_vector in zip(inputs, targets):\n",
    "            \n",
    "            self.backprop(inputs, targets)\n",
    "        \n",
    "        \n",
    "            accu_test = self.accu(testing)\n",
    "            accu_train = self.accu(training)\n",
    "                \n",
    "            #print (accu_train)\n",
    "            \n",
    "            if (self.iteration == 1 or self.iteration % 10 == 0):\n",
    "                self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "                \n",
    "        if (self.iteration % 10 != 0):\n",
    "            self.print_message_iter(self.iteration,accu_test,accu_train,self.ETAepoch(self.start_time))\n",
    "\n",
    "        # Final message\n",
    "        print('\\n-- Training Session End (%s) --' % (dt.datetime.now()))\n",
    "\n",
    "    def feed_forward(self, inputs):\n",
    "            #da fare successivamente a monte    input_with_bias = np.append(input_vector, 1) \n",
    "        output = np.dot(inputs, self.layers)\n",
    "        \n",
    "        output = special.expit(output)\n",
    "       # print(output)\n",
    "        #print()\n",
    "\n",
    "        return output #NumEsempi x neuroni; NumEsempi x classi\n",
    "\n",
    "    def backprop(self, inputs, target):\n",
    "        c = 10**(-4) + 10**(-1)/math.sqrt(self.iteration)  # Learning coefficient\n",
    "        outputs = self.feed_forward(inputs)\n",
    "       # print(outputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(np.mean(self.layers))\n",
    "        output_deltas = outputs * (1 - outputs) * (outputs - target) #NumEx x Output\n",
    "        #print(hidden_outputs.shape)\n",
    "        #print((np.dot(output_deltas.T, hidden_outputs)).shape)\n",
    "        print(outputs-target)\n",
    "        #print(output_deltas)\n",
    "        #print(target)   \n",
    "       # print((self.layers).shape)\n",
    "        self.layers -= c * (np.dot(inputs.T, output_deltas))\n",
    "        #print((np.dot(inputs.T, output_deltas)))\n",
    "        #print((self.layers).shape)\n",
    "\n",
    "        #print(np.mean(self.layers))\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        return self.feed_forward(inputs)\n",
    "\n",
    "   #def predict_one(self, inputs):\n",
    "   #     return np.argmax(self.feed_forward(input_vector)[-1])\n",
    "    \n",
    "    def accu(self, testing):\n",
    "        #res= np.zeros((10, 2))\n",
    "        res=0\n",
    "        #se giusto aggiungo 1 ad entrambe le colonne di res (colonne = giusti, totali)\n",
    "        predicted = self.predict(testing[0])\n",
    "        for k in range(len(testing[1])):\n",
    "            if (predicted[k] >= 0.1) and testing[1][k] == 4:\n",
    "            #if self.predict_one(testing[0][k]) == testing[1][k]:\n",
    "                res += 1\n",
    "        #total = np.sum(res, axis=0)\n",
    "        \n",
    "        return res/len(testing[0])*100\n",
    "    \n",
    "    def is_stop_function(self, accuracy):\n",
    "        if self.stop_f==0:\n",
    "            if accuracy > self.best + self.stop_p or self.iteration == 0:\n",
    "                self.best = accuracy\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        elif self.stop_f==1:\n",
    "            if self.iteration>=self.limit_epoch:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    def print_message_iter(self,iteration,accu_test,accu_train,eta):\n",
    "        len_eta = len(eta)\n",
    "        space_fill = 6 - len_eta\n",
    "        eta = \"(\"+eta+\")\"\n",
    "        for _ in range(space_fill):\n",
    "            eta += \" \"\n",
    "        message = 'Epoch '+str(self.iteration).zfill(3) + \" \"+eta+\" \"+'Accuracy TRAIN: '+str(accu_train).zfill(4)+'%\\t'+'Accuracy TEST: '+str(accu_test).zfill(4)+'%\\t'\n",
    "        print(message)\n",
    "       # print(self.layers[200:210])\n",
    "        \n",
    "\n",
    "        \n",
    "    def ETAepoch(self,start_time):\n",
    "        diff = dt.datetime.now() - self.start_time\n",
    "        eta = divmod(diff.days * 86400 + diff.seconds, 60)\n",
    "        if eta[0] != 0:\n",
    "            ret = str(eta[0])+\"m\"\n",
    "        else:\n",
    "            ret = \"\"\n",
    "        ret += str(eta[1])+\"s\"\n",
    "        return ret\n",
    "    def getWeight(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=TRAINING\n",
    "for i in range(t[0].shape[0]):\n",
    "    for j in range(t[0].shape[1]):\n",
    "        t[0][i,j]-=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Training Session Start (2019-05-13 14:28:16.827492) --\n",
      "Stop Function: after 300 epochs\n",
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [-0.5]\n",
      " ...\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n",
      "Epoch 001 (0s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 010 (1s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 020 (1s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 030 (2s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 040 (3s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 050 (4s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 060 (5s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 070 (6s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 080 (7s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 090 (8s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 100 (9s)     Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 110 (10s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 120 (10s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 130 (11s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 140 (12s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 150 (13s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 160 (14s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 170 (15s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 180 (16s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 190 (17s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 200 (18s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 210 (19s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 220 (19s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 230 (20s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 240 (21s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 250 (22s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 260 (23s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 270 (24s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 280 (25s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 290 (26s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "[[ 0.]\n",
      " [ 0.]\n",
      " [-1.]\n",
      " ...\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "Epoch 300 (27s)    Accuracy TRAIN: 00.0%\tAccuracy TEST: 9.82%\t\n",
      "\n",
      "-- Training Session End (2019-05-13 14:28:44.002146) --\n"
     ]
    }
   ],
   "source": [
    "nnM = NN_b(neurons=100, stop_function=1, stop_parameter=0.01)\n",
    "nnM.train([t[0][0:10000], t[1][0:10000]], TESTING)\n",
    "#nnM.train(([t[0:10],TRAINING[1][0:10]], TESTING))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[271.61371738],\n",
       "       [270.56754725],\n",
       "       [268.366098  ],\n",
       "       [264.9271625 ],\n",
       "       [259.68054613],\n",
       "       [252.53052825],\n",
       "       [243.72510663],\n",
       "       [234.37539125],\n",
       "       [225.25978475],\n",
       "       [216.60075938]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnM.layers[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
